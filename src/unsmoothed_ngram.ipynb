{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import collections\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(directory):\n",
    "    text_files=[]\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('txt.tra'):\n",
    "            text_files.append(filename)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['udhr-uzn_latn.txt.tra',\n",
       " 'udhr-hat_kreyol.txt.tra',\n",
       " 'udhr-eng.txt.tra',\n",
       " 'udhr-kri.txt.tra',\n",
       " 'udhr-vmw.txt.tra',\n",
       " 'udhr-lun.txt.tra',\n",
       " 'udhr-bcl.txt.tra',\n",
       " 'udhr-uig_latn.txt.tra',\n",
       " 'udhr-nya_chinyanja.txt.tra',\n",
       " 'udhr-cjk.txt.tra',\n",
       " 'udhr-sco.txt.tra',\n",
       " 'udhr-deu_1901.txt.tra',\n",
       " 'udhr-cjk_AO.txt.tra',\n",
       " 'udhr-lad.txt.tra',\n",
       " 'udhr-pcm.txt.tra',\n",
       " 'udhr-hni.txt.tra',\n",
       " 'udhr-als.txt.tra',\n",
       " 'udhr-hms.txt.tra',\n",
       " 'udhr-nbl.txt.tra',\n",
       " 'udhr-qvc.txt.tra',\n",
       " 'udhr-bre.txt.tra',\n",
       " 'udhr-ssw.txt.tra',\n",
       " 'udhr-min.txt.tra',\n",
       " 'udhr-nya_chechewa.txt.tra',\n",
       " 'udhr-xho.txt.tra',\n",
       " 'udhr-ccx.txt.tra',\n",
       " 'udhr-quy.txt.tra',\n",
       " 'udhr-kqn.txt.tra',\n",
       " 'udhr-swh.txt.tra',\n",
       " 'udhr-qxa.txt.tra',\n",
       " 'udhr-nld.txt.tra',\n",
       " 'udhr-koo.txt.tra',\n",
       " 'udhr-njo.txt.tra',\n",
       " 'udhr-mly_latn.txt.tra',\n",
       " 'udhr-blu.txt.tra',\n",
       " 'udhr-tiv.txt.tra',\n",
       " 'udhr-nds.txt.tra',\n",
       " 'udhr-ido.txt.tra',\n",
       " 'udhr-qxu.txt.tra',\n",
       " 'udhr-deu_1996.txt.tra',\n",
       " 'udhr-run.txt.tra',\n",
       " 'udhr-yao.txt.tra',\n",
       " 'udhr-cha.txt.tra',\n",
       " 'udhr-som.txt.tra',\n",
       " 'udhr-xsm.txt.tra',\n",
       " 'udhr-ndo.txt.tra',\n",
       " 'udhr-amc.txt.tra',\n",
       " 'udhr-nyn.txt.tra',\n",
       " 'udhr-zul.txt.tra',\n",
       " 'udhr-snk.txt.tra',\n",
       " 'udhr-nba.txt.tra',\n",
       " 'udhr-ztu.txt.tra',\n",
       " 'udhr-kin.txt.tra',\n",
       " 'udhr-hea.txt.tra',\n",
       " 'udhr-hat_popular.txt.tra']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir='/home/himangsu/Code/Python/notebookenv/ML_Models/NLP/N-gram_Language_Models-main/data/train'\n",
    "\n",
    "get_training_data(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_data(directory):\n",
    "    text_files_dev=[]\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('txt.dev'):\n",
    "            text_files_dev.append(filename)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return text_files_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['udhr-nya_chinyanja.txt.dev',\n",
       " 'udhr-mly_latn.txt.dev',\n",
       " 'udhr-ztu.txt.dev',\n",
       " 'udhr-ido.txt.dev',\n",
       " 'udhr-amc.txt.dev',\n",
       " 'udhr-ssw.txt.dev',\n",
       " 'udhr-hea.txt.dev',\n",
       " 'udhr-nds.txt.dev',\n",
       " 'udhr-als.txt.dev',\n",
       " 'udhr-qvc.txt.dev',\n",
       " 'udhr-hni.txt.dev',\n",
       " 'udhr-xsm.txt.dev',\n",
       " 'udhr-uzn_latn.txt.dev',\n",
       " 'udhr-nbl.txt.dev',\n",
       " 'udhr-hms.txt.dev',\n",
       " 'udhr-snk.txt.dev',\n",
       " 'udhr-qxa.txt.dev',\n",
       " 'udhr-uig_latn.txt.dev',\n",
       " 'udhr-nyn.txt.dev',\n",
       " 'udhr-bre.txt.dev',\n",
       " 'udhr-vmw.txt.dev',\n",
       " 'udhr-yao.txt.dev',\n",
       " 'udhr-koo.txt.dev',\n",
       " 'udhr-quy.txt.dev',\n",
       " 'udhr-nld.txt.dev',\n",
       " 'udhr-cha.txt.dev',\n",
       " 'udhr-cjk_AO.txt.dev',\n",
       " 'udhr-pcm.txt.dev',\n",
       " 'udhr-deu_1996.txt.dev',\n",
       " 'udhr-hat_popular.txt.dev',\n",
       " 'udhr-qxu.txt.dev',\n",
       " 'udhr-kri.txt.dev',\n",
       " 'udhr-tiv.txt.dev',\n",
       " 'udhr-deu_1901.txt.dev',\n",
       " 'udhr-kin.txt.dev',\n",
       " 'udhr-bcl.txt.dev',\n",
       " 'udhr-ndo.txt.dev',\n",
       " 'udhr-nya_chechewa.txt.dev',\n",
       " 'udhr-swh.txt.dev',\n",
       " 'udhr-sco.txt.dev',\n",
       " 'udhr-kqn.txt.dev',\n",
       " 'udhr-eng.txt.dev',\n",
       " 'udhr-lun.txt.dev',\n",
       " 'udhr-cjk.txt.dev',\n",
       " 'udhr-min.txt.dev',\n",
       " 'udhr-zul.txt.dev',\n",
       " 'udhr-run.txt.dev',\n",
       " 'udhr-njo.txt.dev',\n",
       " 'udhr-som.txt.dev',\n",
       " 'udhr-ccx.txt.dev',\n",
       " 'udhr-lad.txt.dev',\n",
       " 'udhr-nba.txt.dev',\n",
       " 'udhr-hat_kreyol.txt.dev',\n",
       " 'udhr-xho.txt.dev',\n",
       " 'udhr-blu.txt.dev']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir='/home/himangsu/Code/Python/notebookenv/ML_Models/NLP/N-gram_Language_Models-main/data/dev'\n",
    "\n",
    "get_dev_data(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename,directory):\n",
    "    file_name=directory+'/'+filename\n",
    "    script=\"\"\n",
    "\n",
    "    with open(file_name,\"r+\") as f:\n",
    "        text=f.readlines()\n",
    "\n",
    "        for line in text:\n",
    "            line= \"<s>\"+line+\"<s>\"\n",
    "            script=script+line\n",
    "        \n",
    "        text=script.replace('\\n',\"\")\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>inson huquqlari umumjahon deklaratsiyasi<s><s>yil dekabrda birlashgan millatlar tashkiloti bosh assambleyasining iii koʻrsatmasi orqali qabul qilingan va eʼlon qilingan<s><s>preambula<s><s>inson oilasi barcha aʼzolariga hos boʻlgan qadr qimmat hamda ularning teng va ajralmas huquqlarini tan olish erkinlik adolat va yalpi tinchlikning asosi boʻlishini eʼtiborga olib<s><s>inson huquqlarini mensimaslik va oyoq osti qilish odamzod vijdonini oʻrtayotgan vahshiylarcha qilmishlarga olib kelganini hamda kishilar soʻz va maslak erkinligi sohibi boʻlib qoʻrquv va muhtojlikdan holi boʻlib yashaydigan dunyoni bunyod etish odamlarning nufuzli intilishi deb eʼlon qilinganligini eʼtiborga olib<s><s>inson soʻnggi chora sifatida zulm va istibdodga qarshi isyon qilib bosh koʻtarishga majbur boʻlmasligining oldini olish maqsadida inson huquqlarni qonun izmi bilan muhofaza etilishi zarurligini eʼtiborga olib<s><s>xalqlar oʻrtasida doʻstona munosabatlarni rivojlantirishga koʻmaklashish zarurligini eʼtiborga olib<s><s>birlashgan millatlarning xalqlari ustavda insonning asosiy huquqlarni qadr qimmati va inson shaxsning benazirligiga hamda erkaklar va ayollarning teng huquqligiga oʻz ishonchlarini tasdiqlaganliklarni hamda katta huquq bilan ijtimoiy taraqqiyot va turmush sharoitini yaxshilashga yordam berishga qaror qilganliklarni eʼtiborga olib<s><s>aʼzo boʻlgan davlatlar birlashgan millatlar tashkiloti bilan hamkorlikda inson huquqlari va asosiy erkinliklarni yalpi hurmat qilish va rioya etishga yordamlashish majburiyatini olganliklarni eʼtiborga olib<s><s>ushbu huquqlar va erkinliklar tusini yalpisiga tushunib olish mazkur majburiyatni toʻla toʻkis bajarilishi uchun juda katta ahamiyatga ega boʻladi<s><s>bosh assambleya<s><s>inson huquqlari mazkur umumjahon deklaratsiyasini barcha xalqlar va barcha davlatlar bajarishiga intilishi lozim boʻlgan vazifa sifatida eʼlon qilar ekan bundan muddao shuki har bir inson va jamiyatning har bir tashkiloti hamisha ana shu deklaratsiyani nazarda tutib maʼrifat va ilm yoʻli bilan ushbu huquqlar va erkinliklarning hurmat qilinishiga yordam berishga intilishlari hamda milliy va xalqaro taraqqiyparvar tadbirla yoʻli bilan ham ushbu huquqlar va erkinliklarning tashkilotga aʼzo boʻlgan davlatlar xalqlari oʻrtasida va mazkur davlatlarning yurisdiksiyasidagi hududlarda yashayotgan xalqlar oʻrtasida yalpisiga va samarali tan olinishiga kerak<s><s>modda<s><s>barcha odamlar erkin qadr qimmat va huquqlarda teng boʻlib tugʻiladilar ular aql va vijdon sohibidirlar va bir birlariga birodarlarcha muomala qilishlari zarur<s><s>modda<s><s>har bir inson biror bir ayirmachiliksiz irqi terisining rangi jinsi tili dini siyosiy eʼtiqodi yoki boshqa eʼtiqodlaridan milliy yoki ijtimoiy kelib chiqishidan mulkiy ahvoli qaysi tabaqaga mansubligi va boshqa holatlaridan qatʼi nazar mazkur deklaratsiyada eʼlon qilingan barcha huquqlar va erkinliklar sohibi boʻlishi kerak<s><s>bundan tashqari inson mansub boʻlgan mamlakat yoki hududning siyosiy huquqiy yoki xalqaro maqomidan qatʼi nazar ushbu hudud mustaqilmi vasiylikdami oʻzini oʻzi boshqaradimi yoki mustaqilligi biror bir tarzda cheklanganmi bundan qatʼi nazar sira ayirmachilik boʻlmasligi kerak<s><s>modda<s><s>har bir inson yashash erkinlik va shaxsiy daxlsizlik huquqiga egadir<s><s>modda<s><s>hech kim qullikda yoki qaramlikda saqlanishi mumkin emas qullik va qul savdosining barcha turlari taqiqlanadi<s><s>modda<s><s>hech kim azob uqubatga yoki vahshiylarcha insonlikka isnod boʻlgan yoki qadr qimmatni xoʻrlaydigan muomala va jazoga mustahiq boʻlmasligi kerak<s><s>modda<s><s>har bir inson qayerda boʻlishidan qatʼi nazar oʻzining huquq subyekti sifatida tan olinishi huquqiga egadir<s><s>modda<s><s>barcha odamlar qonun oldida tengdir va sira ayirmachiliksiz qonun tomonidan babbaravar muhofaza etilishi huquqiga egadir barcha odamlar mazkur deklaratsiyani buzadigan har qanday kamsitishidan teng muhofaza qilinish huquqiga va ana shunday kamsitishga gij gijlashdan teng muhofaza qilinish huquqiga egadirlar<s><s>modda<s><s>har bir inson mabodo uning konstitutsiya yoki qonun berib qoʻygan asosiy huquqlari buzilgudek boʻlsa nufuzli milliy sud tomonidan oʻz huquqlari<s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir='/home/himangsu/Code/Python/notebookenv/ML_Models/NLP/N-gram_Language_Models-main/data/train'\n",
    "file='udhr-uzn_latn.txt.tra'\n",
    "get_data(file,dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(results,resultfile):\n",
    "     column_names = [\"Training_file\", \"Testing_file\", \"Perplexity\", \"N\"]\n",
    "     df=pd.DataFrame(results,columns=column_names)\n",
    "\n",
    "     df.to_csv(resultfile,index=False)\n",
    "     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_token(text):\n",
    "    tokens=[]\n",
    "\n",
    "    for line in text:\n",
    "        word=line.split()\n",
    "\n",
    "        for w in word:\n",
    "            for c in w:\n",
    "                tokens.append(c)\n",
    "\n",
    "    token_counts=Counter(tokens)\n",
    "\n",
    "    new_token=[]\n",
    "\n",
    "    for t in tokens:\n",
    "        if token_counts[t]==1:\n",
    "            new_token.append('<UNK>')\n",
    "        else:\n",
    "            new_token.append(t)\n",
    "    \n",
    "    return new_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsmoothedModel(object):\n",
    "\n",
    "\n",
    "    def __init__(self,n,data):\n",
    "        self.n=n\n",
    "        self.text=data\n",
    "        self.vocabulary=[]\n",
    "        self.count=None\n",
    "        self.context=None\n",
    "        self.tokens=preprocessing_token(self.text)\n",
    "    \n",
    "\n",
    "    def find_count(self,N):\n",
    "        \n",
    "        if self.n==1:\n",
    "            self.context=N\n",
    "        else:\n",
    "            c=ngrams(self.tokens,self.n-1)\n",
    "            self.context=Counter(c)\n",
    "\n",
    "    def unsmoothed(self):\n",
    "\n",
    "        if '<UNK>' not in self.tokens:\n",
    "            self.tokens.append('<UNK>')\n",
    "        N=len(self.tokens)\n",
    "        self.vocabulary=list(set(self.tokens))\n",
    "        model=ngrams(self.tokens,self.n)\n",
    "        self.count=Counter(model)\n",
    "        self.find_count(N)\n",
    "\n",
    "        return self.n, self.vocabulary, self.count, self.context\n",
    "    \n",
    "    def find_Perplexity(self,text,n,Vocab,count,context):\n",
    "        t_tokens = []\n",
    "        for line in text:\n",
    "            word = line.split()\n",
    "            for w in word:\n",
    "                for c in w:\n",
    "                    t_tokens.append(c)\n",
    "        # appending the \"<UNK> token in case my vocab does not have this token\"\n",
    "        new_t_tokens = []\n",
    "        for tt in t_tokens:\n",
    "            if tt in Vocab:\n",
    "                new_t_tokens.append(tt)\n",
    "            else:\n",
    "                new_t_tokens.append(\"<UNK>\")\n",
    "        # finding the probability of the model\n",
    "        probability, log_probability = 0, 0\n",
    "        # to find the denominator\n",
    "        model = ngrams(new_t_tokens, n)\n",
    "        for item in model:\n",
    "            # unigram model (the context is N: length of token)\n",
    "            if n == 1:\n",
    "                log_probability = np.log2(count[item] / context)\n",
    "            # for n-gram model where n>=2\n",
    "            else:\n",
    "                if (context[item[:-1]] == 0):\n",
    "                    log_probability = 0\n",
    "                else:\n",
    "                    log_probability = np.log2(count[item] / context[item[:-1]])\n",
    "\n",
    "            probability = probability + log_probability\n",
    "        perplexity = np.power(2, (-1 / len(new_t_tokens)) * probability)\n",
    "        return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testmodel(models_values, textfiles_dev, test_dir, output_file):\n",
    "    results1 = []\n",
    "    for index, file_name in enumerate(textfiles_dev):\n",
    "        text = get_data(file_name, test_dir)\n",
    "        perp = []\n",
    "        for index, model in enumerate(models_values):\n",
    "            # finding the perplexity on each model\n",
    "            perp.append(model[0].find_Perplexity(text, model[2], model[3], model[4], model[5]))\n",
    "        # finding the minimum perplexity to find the best model\n",
    "        min_perplex = min(perp)\n",
    "        # getting the best model by checking the index which generate minimum perplexity\n",
    "        best_model = models_values[perp.index(min_perplex)][1]\n",
    "\n",
    "        results1.append((best_model, file_name, min_perplex,1))\n",
    "        # to sort based on dev set file\n",
    "        # data source: https://stackoverflow.com/questions/3121979/how-to-sort-a-list-tuple-of-lists-tuples-by-the-element-at-a-given-index\n",
    "        results1.sort(key=lambda tup: tup[1])  # sorts in place\n",
    "        save_result(results1, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unsmoothed(textfiles_train, train_dir, unsmoothed_n=1):\n",
    "    # this method will train the unsmoothed model\n",
    "    models_values = []\n",
    "    for file_name in textfiles_train:\n",
    "        text = get_data(file_name, train_dir)\n",
    "        model = UnsmoothedModel(unsmoothed_n, text)\n",
    "        n, Vocab, freq, context = model.unsmoothed()\n",
    "        models_values.append((model, file_name, n, Vocab, freq, context))\n",
    "    return models_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir ='/home/himangsu/Code/Python/notebookenv/ML_Models/NLP/N-gram_Language_Models-main/data/train'\n",
    "\n",
    "textfiles_train = get_training_data(train_dir)\n",
    "\n",
    "test_dir = '/home/himangsu/Code/Python/notebookenv/ML_Models/NLP/N-gram_Language_Models-main/data/dev'\n",
    "\n",
    "textfiles_dev = get_dev_data(test_dir)\n",
    "output_file='result.csv'\n",
    "\n",
    "models_values = train_unsmoothed(textfiles_train, train_dir,1)\n",
    "testmodel(models_values, textfiles_dev, test_dir, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
